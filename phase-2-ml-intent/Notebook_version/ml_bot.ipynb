{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c7f73b",
   "metadata": {},
   "source": [
    "# Cell 1: Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a8db7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Import required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import random\n",
    "import joblib\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb2b9e",
   "metadata": {},
   "source": [
    "# Cell 2: Data Preparation Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930c7a1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2: Data Preparation Class Definition\n",
    "\"\"\"\n",
    "Data Preparation for ML Chatbot\n",
    "Handles dataset loading, preprocessing, and splitting\n",
    "\"\"\"\n",
    "\n",
    "class IntentDataPreprocessor:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.data = None\n",
    "        self.df = None\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load intent data from JSON file\"\"\"\n",
    "        with open(self.data_path, 'r', encoding='utf-8') as f:\n",
    "            self.data = json.load(f)\n",
    "        return self.data\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and preprocess text data\"\"\"\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove special characters and digits\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        # Tokenize and remove stopwords\n",
    "        tokens = text.split()\n",
    "        tokens = [token for token in tokens if token not in self.stop_words]\n",
    "        \n",
    "        # Apply stemming\n",
    "        tokens = [self.stemmer.stem(token) for token in tokens]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def create_training_data(self):\n",
    "        \"\"\"Create training data from intents\"\"\"\n",
    "        if not self.data:\n",
    "            self.load_data()\n",
    "            \n",
    "        patterns = []\n",
    "        labels = []\n",
    "        \n",
    "        for intent in self.data['intents']:\n",
    "            for pattern in intent['patterns']:\n",
    "                # Preprocess each pattern\n",
    "                processed_pattern = self.preprocess_text(pattern)\n",
    "                patterns.append(processed_pattern)\n",
    "                labels.append(intent['tag'])\n",
    "        \n",
    "        # Create DataFrame\n",
    "        self.df = pd.DataFrame({\n",
    "            'text': patterns,\n",
    "            'label': labels\n",
    "        })\n",
    "        \n",
    "        # Encode labels\n",
    "        encoded_labels = self.label_encoder.fit_transform(labels)\n",
    "        \n",
    "        return patterns, encoded_labels\n",
    "    \n",
    "    def split_data(self, test_size=0.2, random_state=42):\n",
    "        \"\"\"Split data into training and test sets\"\"\"\n",
    "        if self.df is None:\n",
    "            self.create_training_data()\n",
    "            \n",
    "        X = self.df['text']\n",
    "        y = self.df['label']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "        )\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def get_label_mapping(self):\n",
    "        \"\"\"Get mapping between encoded labels and original tags\"\"\"\n",
    "        return dict(zip(\n",
    "            self.label_encoder.classes_, \n",
    "            range(len(self.label_encoder.classes_))\n",
    "        ))\n",
    "    \n",
    "    def get_class_distribution(self):\n",
    "        \"\"\"Get distribution of classes in the dataset\"\"\"\n",
    "        if self.df is not None:\n",
    "            return self.df['label'].value_counts()\n",
    "        return None\n",
    "\n",
    "print(\"Data Preprocessor class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da76e6c8",
   "metadata": {},
   "source": [
    "# Cell 3: Example usage of Data Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2ae103",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 3: Example usage of Data Preprocessor\n",
    "\n",
    "# Create sample intents data for demonstration\n",
    "sample_intents = {\n",
    "    \"intents\": [\n",
    "        {\n",
    "            \"tag\": \"greeting\",\n",
    "            \"patterns\": [\"Hello\", \"Hi\", \"Hey\", \"Good morning\", \"Good afternoon\"],\n",
    "            \"responses\": [\"Hello! How can I help you?\", \"Hi there!\", \"Greetings!\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"goodbye\",\n",
    "            \"patterns\": [\"Bye\", \"Goodbye\", \"See you later\", \"Take care\"],\n",
    "            \"responses\": [\"Goodbye!\", \"See you soon!\", \"Have a great day!\"]\n",
    "        },\n",
    "        {\n",
    "            \"tag\": \"thanks\",\n",
    "            \"patterns\": [\"Thank you\", \"Thanks\", \"Thanks a lot\", \"I appreciate it\"],\n",
    "            \"responses\": [\"You're welcome!\", \"Happy to help!\", \"Anytime!\"]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save sample data to file\n",
    "with open('sample_intents.json', 'w') as f:\n",
    "    json.dump(sample_intents, f)\n",
    "\n",
    "# Test the preprocessor\n",
    "preprocessor = IntentDataPreprocessor('sample_intents.json')\n",
    "X, y = preprocessor.create_training_data()\n",
    "X_train, X_test, y_train, y_test = preprocessor.split_data()\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Number of classes: {len(preprocessor.label_encoder.classes_)}\")\n",
    "print(\"Class distribution:\")\n",
    "print(preprocessor.get_class_distribution())\n",
    "print(\"\\nLabel mapping:\")\n",
    "print(preprocessor.get_label_mapping())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b118d30",
   "metadata": {},
   "source": [
    "# Cell 4: Model Training Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad6e9ec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 4: Model Training Class Definition\n",
    "\"\"\"\n",
    "Model Training for Intent Classification\n",
    "Trains and evaluates multiple ML algorithms\n",
    "\"\"\"\n",
    "\n",
    "class IntentClassifierTrainer:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.best_model = None\n",
    "        self.vectorizer = None\n",
    "        self.results = {}\n",
    "        \n",
    "    def create_pipelines(self):\n",
    "        \"\"\"Create ML pipelines with different algorithms\"\"\"\n",
    "        self.models = {\n",
    "            'naive_bayes': Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(\n",
    "                    max_features=5000,\n",
    "                    ngram_range=(1, 2),\n",
    "                    stop_words='english',\n",
    "                    min_df=2,\n",
    "                    max_df=0.8\n",
    "                )),\n",
    "                ('classifier', MultinomialNB(alpha=0.1))\n",
    "            ]),\n",
    "            \n",
    "            'svm': Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(\n",
    "                    max_features=5000,\n",
    "                    ngram_range=(1, 2),\n",
    "                    stop_words='english',\n",
    "                    min_df=2,\n",
    "                    max_df=0.8\n",
    "                )),\n",
    "                ('classifier', SVC(\n",
    "                    kernel='linear',\n",
    "                    C=1.0,\n",
    "                    probability=True,\n",
    "                    random_state=42\n",
    "                ))\n",
    "            ]),\n",
    "            \n",
    "            'logistic_regression': Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(\n",
    "                    max_features=5000,\n",
    "                    ngram_range=(1, 2),\n",
    "                    stop_words='english',\n",
    "                    min_df=2,\n",
    "                    max_df=0.8\n",
    "                )),\n",
    "                ('classifier', LogisticRegression(\n",
    "                    C=1.0,\n",
    "                    max_iter=1000,\n",
    "                    random_state=42,\n",
    "                    multi_class='ovr'\n",
    "                ))\n",
    "            ]),\n",
    "            \n",
    "            'random_forest': Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(\n",
    "                    max_features=5000,\n",
    "                    ngram_range=(1, 2),\n",
    "                    stop_words='english',\n",
    "                    min_df=2,\n",
    "                    max_df=0.8\n",
    "                )),\n",
    "                ('classifier', RandomForestClassifier(\n",
    "                    n_estimators=100,\n",
    "                    random_state=42,\n",
    "                    max_depth=10\n",
    "                ))\n",
    "            ])\n",
    "        }\n",
    "    \n",
    "    def train_models(self, X_train, y_train):\n",
    "        \"\"\"Train all models and measure training time\"\"\"\n",
    "        self.create_pipelines()\n",
    "        self.results = {}\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            print(f\"Training {name}...\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            training_time = time.time() - start_time\n",
    "            self.results[name] = {\n",
    "                'model': model,\n",
    "                'training_time': training_time\n",
    "            }\n",
    "            \n",
    "            print(f\"  {name} trained in {training_time:.2f} seconds\")\n",
    "    \n",
    "    def evaluate_models(self, X_test, y_test):\n",
    "        \"\"\"Evaluate all models on test data\"\"\"\n",
    "        for name in self.models.keys():\n",
    "            model = self.results[name]['model']\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            self.results[name]['accuracy'] = accuracy\n",
    "            self.results[name]['predictions'] = y_pred\n",
    "            \n",
    "            print(f\"{name.upper():<20} Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    def get_best_model(self):\n",
    "        \"\"\"Select the best performing model\"\"\"\n",
    "        best_accuracy = 0\n",
    "        best_model_name = None\n",
    "        \n",
    "        for name, result in self.results.items():\n",
    "            if result['accuracy'] > best_accuracy:\n",
    "                best_accuracy = result['accuracy']\n",
    "                best_model_name = name\n",
    "        \n",
    "        if best_model_name:\n",
    "            self.best_model = self.results[best_model_name]['model']\n",
    "            print(f\"\\nBest model: {best_model_name} with accuracy: {best_accuracy:.4f}\")\n",
    "            return self.best_model\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def detailed_classification_report(self, X_test, y_test, label_encoder):\n",
    "        \"\"\"Generate detailed classification report for best model\"\"\"\n",
    "        if self.best_model:\n",
    "            y_pred = self.best_model.predict(X_test)\n",
    "            \n",
    "            # Convert encoded labels back to original names\n",
    "            y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "            y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "            \n",
    "            print(\"\\nDetailed Classification Report:\")\n",
    "            print(classification_report(y_test_labels, y_pred_labels))\n",
    "            \n",
    "            return classification_report(y_test_labels, y_pred_labels, output_dict=True)\n",
    "        return None\n",
    "    \n",
    "    def plot_confusion_matrix(self, X_test, y_test, label_encoder, figsize=(12, 10)):\n",
    "        \"\"\"Plot confusion matrix for best model\"\"\"\n",
    "        if self.best_model:\n",
    "            y_pred = self.best_model.predict(X_test)\n",
    "            y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "            y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "            \n",
    "            cm = confusion_matrix(y_test_labels, y_pred_labels, \n",
    "                                labels=label_encoder.classes_)\n",
    "            \n",
    "            plt.figure(figsize=figsize)\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                       xticklabels=label_encoder.classes_,\n",
    "                       yticklabels=label_encoder.classes_)\n",
    "            plt.title('Confusion Matrix')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.yticks(rotation=0)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"Save the best model to disk\"\"\"\n",
    "        if self.best_model:\n",
    "            joblib.dump(self.best_model, filepath)\n",
    "            print(f\"Model saved to {filepath}\")\n",
    "        else:\n",
    "            print(\"No model to save. Train a model first.\")\n",
    "    \n",
    "    def save_vectorizer(self, filepath):\n",
    "        \"\"\"Save the TF-IDF vectorizer to disk\"\"\"\n",
    "        if self.best_model:\n",
    "            vectorizer = self.best_model.named_steps['tfidf']\n",
    "            joblib.dump(vectorizer, filepath)\n",
    "            print(f\"Vectorizer saved to {filepath}\")\n",
    "\n",
    "print(\"Model Trainer class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f774467",
   "metadata": {},
   "source": [
    "# Cell 5: Example usage of Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9a0b9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 5: Example usage of Model Trainer\n",
    "# Using the sample data from previous cell\n",
    "\n",
    "# Train models\n",
    "trainer = IntentClassifierTrainer()\n",
    "trainer.train_models(X_train, y_train)\n",
    "trainer.evaluate_models(X_test, y_test)\n",
    "trainer.get_best_model()\n",
    "\n",
    "# Generate detailed reports\n",
    "trainer.detailed_classification_report(X_test, y_test, preprocessor.label_encoder)\n",
    "trainer.plot_confusion_matrix(X_test, y_test, preprocessor.label_encoder)\n",
    "\n",
    "# Save the best model\n",
    "trainer.save_model('best_intent_classifier.joblib')\n",
    "trainer.save_vectorizer('tfidf_vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4729f8f7",
   "metadata": {},
   "source": [
    "# Cell 6: Chatbot Application Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb66663",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 6: Chatbot Application Class Definition\n",
    "\"\"\"\n",
    "ML-Powered Chatbot\n",
    "Main chatbot application using trained ML model\n",
    "\"\"\"\n",
    "\n",
    "class MLChatbot:\n",
    "    def __init__(self, intents_file, model_file=None, vectorizer_file=None):\n",
    "        self.intents_file = intents_file\n",
    "        self.model_file = model_file\n",
    "        self.vectorizer_file = vectorizer_file\n",
    "        \n",
    "        # Load intents data\n",
    "        self.preprocessor = IntentDataPreprocessor(intents_file)\n",
    "        self.intents_data = self.preprocessor.load_data()\n",
    "        self.intents = self.intents_data['intents']\n",
    "        \n",
    "        # Initialize model and vectorizer\n",
    "        self.model = None\n",
    "        self.vectorizer = None\n",
    "        self.label_encoder = None\n",
    "        \n",
    "        # Context tracking\n",
    "        self.context = {}\n",
    "        self.conversation_history = []\n",
    "        \n",
    "        # Load or train model\n",
    "        if model_file and vectorizer_file:\n",
    "            self.load_model(model_file, vectorizer_file)\n",
    "        else:\n",
    "            self.train_model()\n",
    "    \n",
    "    def train_model(self):\n",
    "        \"\"\"Train the intent classification model\"\"\"\n",
    "        print(\"Training ML model...\")\n",
    "        \n",
    "        # Prepare data\n",
    "        X, y = self.preprocessor.create_training_data()\n",
    "        X_train, X_test, y_train, y_test = self.preprocessor.split_data()\n",
    "        self.label_encoder = self.preprocessor.label_encoder\n",
    "        \n",
    "        # Train models\n",
    "        trainer = IntentClassifierTrainer()\n",
    "        trainer.train_models(X_train, y_train)\n",
    "        trainer.evaluate_models(X_test, y_test)\n",
    "        trainer.get_best_model()\n",
    "        \n",
    "        self.model = trainer.best_model\n",
    "        self.vectorizer = self.model.named_steps['tfidf']\n",
    "        \n",
    "        print(\"Model training completed!\")\n",
    "    \n",
    "    def load_model(self, model_file, vectorizer_file):\n",
    "        \"\"\"Load pre-trained model and vectorizer\"\"\"\n",
    "        try:\n",
    "            self.model = joblib.load(model_file)\n",
    "            self.vectorizer = joblib.load(vectorizer_file)\n",
    "            self.label_encoder = self.preprocessor.label_encoder\n",
    "            print(\"Model loaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            print(\"Training new model instead...\")\n",
    "            self.train_model()\n",
    "    \n",
    "    def preprocess_input(self, text):\n",
    "        \"\"\"Preprocess user input using the same method as training\"\"\"\n",
    "        return self.preprocessor.preprocess_text(text)\n",
    "    \n",
    "    def predict_intent(self, user_input):\n",
    "        \"\"\"Predict intent from user input\"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded or trained\")\n",
    "        \n",
    "        # Preprocess input\n",
    "        processed_input = self.preprocess_input(user_input)\n",
    "        \n",
    "        # Predict intent\n",
    "        prediction = self.model.predict([processed_input])[0]\n",
    "        confidence = np.max(self.model.predict_proba([processed_input]))\n",
    "        \n",
    "        # Convert back to intent tag\n",
    "        intent_tag = self.label_encoder.inverse_transform([prediction])[0]\n",
    "        \n",
    "        return intent_tag, confidence, processed_input\n",
    "    \n",
    "    def get_response(self, intent_tag, confidence_threshold=0.6):\n",
    "        \"\"\"Get response for predicted intent\"\"\"\n",
    "        if confidence_threshold and confidence < confidence_threshold:\n",
    "            return self.get_fallback_response()\n",
    "        \n",
    "        for intent in self.intents:\n",
    "            if intent['tag'] == intent_tag:\n",
    "                response = random.choice(intent['responses'])\n",
    "                return response\n",
    "        \n",
    "        return self.get_fallback_response()\n",
    "    \n",
    "    def get_fallback_response(self):\n",
    "        \"\"\"Get response when intent is not recognized\"\"\"\n",
    "        fallback_responses = [\n",
    "            \"I'm not sure I understand. Could you rephrase that?\",\n",
    "            \"That's interesting! Could you tell me more?\",\n",
    "            \"I'm still learning. Could you try asking in a different way?\",\n",
    "            \"I want to make sure I understand correctly. Could you elaborate?\",\n",
    "            \"That's outside my current knowledge. Maybe ask me something else?\",\n",
    "            \"I'm designed to help with various topics. Could you try rephrasing?\",\n",
    "            \"I appreciate your message! Could you provide more context?\",\n",
    "            \"I'm here to assist you. Could you clarify what you mean?\",\n",
    "            \"That's given me something to think about! Want to try another topic?\",\n",
    "            \"I'm constantly learning. Could you ask me something different?\"\n",
    "        ]\n",
    "        return random.choice(fallback_responses)\n",
    "    \n",
    "    def update_context(self, user_input, intent_tag, response):\n",
    "        \"\"\"Update conversation context\"\"\"\n",
    "        self.conversation_history.append({\n",
    "            'user_input': user_input,\n",
    "            'intent': intent_tag,\n",
    "            'response': response,\n",
    "            'timestamp': np.datetime64('now')\n",
    "        })\n",
    "        \n",
    "        # Keep only last 10 messages\n",
    "        if len(self.conversation_history) > 10:\n",
    "            self.conversation_history.pop(0)\n",
    "    \n",
    "    def chat(self):\n",
    "        \"\"\"Main chat loop\"\"\"\n",
    "        print(\"🤖 ML-Powered Chatbot: Hello! I'm now using Machine Learning!\")\n",
    "        print(\"💡 I can understand your intent and respond appropriately\")\n",
    "        print(\"💬 Type 'quit' to end our conversation\\n\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\"You: \").strip()\n",
    "                \n",
    "                if not user_input:\n",
    "                    print(\"Bot: I notice you didn't type anything. Is everything okay?\")\n",
    "                    continue\n",
    "                \n",
    "                if user_input.lower() in ['quit', 'exit', 'bye', 'goodbye']:\n",
    "                    print(\"Bot: Thank you for chatting! I'm learning from every conversation!\")\n",
    "                    break\n",
    "                \n",
    "                # Predict intent and get response\n",
    "                intent_tag, confidence, processed_input = self.predict_intent(user_input)\n",
    "                response = self.get_response(intent_tag)\n",
    "                \n",
    "                # Update context\n",
    "                self.update_context(user_input, intent_tag, response)\n",
    "                \n",
    "                # Display response with confidence (for educational purposes)\n",
    "                print(f\"Bot: {response}\")\n",
    "                print(f\"    [Detected: {intent_tag} | Confidence: {confidence:.2f}]\")\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\\nBot: Thanks for the conversation! Come back anytime!\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Bot: I encountered an error: {str(e)}\")\n",
    "                print(\"Let's continue our conversation!\")\n",
    "    \n",
    "    def evaluate_on_test_set(self):\n",
    "        \"\"\"Evaluate model performance on test set\"\"\"\n",
    "        from sklearn.metrics import accuracy_score, classification_report\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = self.preprocessor.split_data()\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        y_test_labels = self.label_encoder.inverse_transform(y_test)\n",
    "        y_pred_labels = self.label_encoder.inverse_transform(y_pred)\n",
    "        \n",
    "        print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test_labels, y_pred_labels))\n",
    "        \n",
    "        return accuracy\n",
    "\n",
    "print(\"ML Chatbot class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0494bc",
   "metadata": {},
   "source": [
    "# Cell 7: Example usage of the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9781f9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 7: Example usage of the Chatbot\n",
    "# Initialize chatbot with our sample data and trained model\n",
    "chatbot = MLChatbot(\n",
    "    intents_file='sample_intents.json',\n",
    "    model_file='best_intent_classifier.joblib',\n",
    "    vectorizer_file='tfidf_vectorizer.joblib'\n",
    ")\n",
    "\n",
    "# Test the chatbot with some sample inputs\n",
    "test_inputs = [\n",
    "    \"Hello there!\",\n",
    "    \"Thank you for your help\",\n",
    "    \"Goodbye for now\",\n",
    "    \"What's the weather like?\"  # This should trigger fallback response\n",
    "]\n",
    "\n",
    "print(\"Testing chatbot with sample inputs:\\n\")\n",
    "for input_text in test_inputs:\n",
    "    print(f\"You: {input_text}\")\n",
    "    intent_tag, confidence, processed_input = chatbot.predict_intent(input_text)\n",
    "    response = chatbot.get_response(intent_tag)\n",
    "    print(f\"Bot: {response}\")\n",
    "    print(f\"    [Detected: {intent_tag} | Confidence: {confidence:.2f}]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17fc576",
   "metadata": {},
   "source": [
    "# Cell 8: Interactive Chat Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d1886",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 8: Interactive Chat Session\n",
    "# Uncomment the following line to start an interactive chat session\n",
    "# chatbot.chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ee3bfb",
   "metadata": {},
   "source": [
    "# Cell 9: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7eb57d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 9: Model Evaluation\n",
    "# Evaluate the model performance on the test set\n",
    "print(\"Evaluating model performance...\")\n",
    "accuracy = chatbot.evaluate_on_test_set()\n",
    "print(f\"\\nOverall Model Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
